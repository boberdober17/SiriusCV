{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CITYSCAPES_DATASET=/home/rvygon/data/DeepLab/video\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import *\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "import time\n",
    "import functools\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "import random\n",
    "%env CITYSCAPES_DATASET = /home/rvygon/data/DeepLab/video\n",
    "from tensorflow.metrics import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "EPOCHS = 50\n",
    "EPOCHS_PER_EVAL = 1\n",
    "BATCH_SIZE = 1\n",
    "TOTAL_SIZE = 1\n",
    "VAL_SIZE = 599\n",
    "SCALE_RATE = 4\n",
    "IMG_SHAPE = (int(1024/SCALE_RATE), int(2048/SCALE_RATE), 3)\n",
    "VERBOSE = 1\n",
    "START_INDEX = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### AUGMENTATION BLOCK\n",
    "\n",
    "def flip_img(horizontal_flip, image, label):\n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "        image, label = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                   lambda: (tf.image.flip_left_right(image), tf.image.flip_left_right(label)),\n",
    "                                   lambda: (image, label))\n",
    "    return image, label            \n",
    "\n",
    "def crop_img(crop_rate, image, label):\n",
    "    if crop_rate is not None:\n",
    "        image = tf.image.resize_images(tf.image.central_crop(image, crop_rate), (IMG_SHAPE[0], IMG_SHAPE[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        label = tf.image.resize_images(tf.image.central_crop(label, crop_rate), (IMG_SHAPE[0], IMG_SHAPE[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "def _augment(image,\n",
    "             label,\n",
    "             hue_delta=0,\n",
    "             horisontal_flip=False,\n",
    "             width_shift_range=0,\n",
    "             height_shift_range=0,\n",
    "             crop_rate=0.25):\n",
    "    if hue_delta:\n",
    "        image = tf.image.random_hue(image, hue_delta)\n",
    "    image, label = flip_img(horisontal_flip, image, label)   \n",
    "    image, label = crop_img(crop_rate, image, label)\n",
    "    return image, label\n",
    "def to_tensor(image, label):\n",
    "    return image, label\n",
    "\n",
    "tr_cfg = {\n",
    "    'hue_delta': 0.05,\n",
    "    'horisontal_flip': True,\n",
    "    'crop_rate' : 0.25\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell once\n",
    "#%run  cityscapesscripts/preparation/createTrainIdLabelImgs\n",
    "def upd_print(str):\n",
    "    sys.stdout.write('\\r')       \n",
    "    sys.stdout.write(str)\n",
    "    sys.stdout.flush()\n",
    "\n",
    "def tversky_loss(y_true, y_pred):\n",
    "    alpha = 0.5\n",
    "    beta  = 0.5\n",
    "    \n",
    "    ones = K.ones(K.shape(y_true))\n",
    "    p0 = y_pred      # proba that pixels are class i\n",
    "    p1 = ones - y_pred # proba that pixels are not class i\n",
    "    g0 = y_true\n",
    "    g1 = ones - y_true\n",
    "    \n",
    "    num = K.sum(p0 * g0, (0, 1, 2))\n",
    "    den = num + alpha * K.sum(p0 * g1, (0, 1, 2)) + beta * K.sum(p1 * g0, (0, 1, 2)) + 1e-8\n",
    "    \n",
    "    T = K.sum(num / den) # when summing over classes, T has dynamic range [0 Ncl]\n",
    "    \n",
    "    classNumber = K.cast(K.shape(y_true)[-1], 'float32') ### equal classNumber = 20.0\n",
    "    return classNumber - T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files input -  100\n",
      "loaded files input -  200\n",
      "loaded files input -  300\n",
      "loaded files input -  400\n",
      "loaded files input -  500\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.python.keras.utils import to_categorical\n",
    "\n",
    "\"\"\"x_train_data, y_train_data = importBatch(TOTAL_SIZE,\n",
    "                                         START_INDEX,\n",
    "                                         VERBOSE,\n",
    "                                         'train',\n",
    "                                         SCALE_RATE)\n",
    "#y_train_data = to_categorical(y_train_data)\n",
    "x_train_data = x_train_data.astype('float32')\n",
    "y_train_data = y_train_data.astype('int32') \"\"\"\n",
    "x_val_data = importBatch(VAL_SIZE,\n",
    "                                            START_INDEX,\n",
    "                                            VERBOSE,\n",
    "                                            'demoVideo',\n",
    "                                          SCALE_RATE)\n",
    "#y_train_data=np.expand_dims(y_train_data,axis=3)\n",
    "#y_val_data = to_categorical(y_val_data)\n",
    "x_val_data = x_val_data.astype('float32')\n",
    "#y_val_data = y_val_data.astype('float32')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imshow(x_val_data[0].astype('uint8'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\"\"\"DeepLab v3 models based on slim library.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "import preprocessing\n",
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.contrib.slim.nets import resnet_v2\n",
    "from tensorflow.contrib import layers as layers_lib\n",
    "from tensorflow.contrib.framework.python.ops import arg_scope\n",
    "from tensorflow.contrib.layers.python.layers import layers\n",
    "from tensorflow.contrib.slim.python.slim.nets import resnet_utils\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import argparse\n",
    "import os\n",
    "import sys\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import debug as tf_debug\n",
    "\n",
    "\n",
    "\n",
    "_NUM_CLASSES = 20\n",
    "_HEIGHT = 256\n",
    "_WIDTH = 512\n",
    "_DEPTH = 3\n",
    "_MIN_SCALE = 0.5\n",
    "_MAX_SCALE = 2.0\n",
    "_IGNORE_LABEL = 255\n",
    "\n",
    "_POWER = 0.9\n",
    "_MOMENTUM = 0.9\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9997\n",
    "\n",
    "_NUM_IMAGES = {\n",
    "    'train': 10582,\n",
    "    'validation': 1449,\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "_BATCH_NORM_DECAY = 0.9997\n",
    "_WEIGHT_DECAY = 5e-4\n",
    "\n",
    "\n",
    "def atrous_spatial_pyramid_pooling(inputs, output_stride, batch_norm_decay, is_training, depth=256):\n",
    "  with tf.device('/GPU:2'):\n",
    "      \"\"\"Atrous Spatial Pyramid Pooling.\n",
    "\n",
    "      Args:\n",
    "        inputs: A tensor of size [batch, height, width, channels].\n",
    "        output_stride: The ResNet unit's stride. Determines the rates for atrous convolution.\n",
    "          the rates are (6, 12, 18) when the stride is 16, and doubled when 8.\n",
    "        batch_norm_decay: The moving average decay when estimating layer activation\n",
    "          statistics in batch normalization.\n",
    "        is_training: A boolean denoting whether the input is for training.\n",
    "        depth: The depth of the ResNet unit output.\n",
    "\n",
    "      Returns:\n",
    "        The atrous spatial pyramid pooling output.\n",
    "      \"\"\"\n",
    "      with tf.variable_scope(\"aspp\"):\n",
    "        if output_stride not in [8, 16]:\n",
    "          raise ValueError('output_stride must be either 8 or 16.')\n",
    "\n",
    "        atrous_rates = [6, 12, 18]\n",
    "        if output_stride == 8:\n",
    "          atrous_rates = [2*rate for rate in atrous_rates]\n",
    "\n",
    "        with tf.contrib.slim.arg_scope(resnet_v2.resnet_arg_scope(batch_norm_decay=batch_norm_decay)):\n",
    "          with arg_scope([layers.batch_norm], is_training=is_training):\n",
    "            inputs_size = tf.shape(inputs)[1:3]\n",
    "            # (a) one 1x1 convolution and three 3x3 convolutions with rates = (6, 12, 18) when output stride = 16.\n",
    "            # the rates are doubled when output stride = 8.\n",
    "            conv_1x1 = layers_lib.conv2d(inputs, depth, [1, 1], stride=1, scope=\"conv_1x1\")\n",
    "            conv_3x3_1 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[0], scope='conv_3x3_1')\n",
    "            conv_3x3_2 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[1], scope='conv_3x3_2')\n",
    "            conv_3x3_3 = resnet_utils.conv2d_same(inputs, depth, 3, stride=1, rate=atrous_rates[2], scope='conv_3x3_3')\n",
    "\n",
    "            # (b) the image-level features\n",
    "            with tf.variable_scope(\"image_level_features\"):\n",
    "              # global average pooling\n",
    "              image_level_features = tf.reduce_mean(inputs, [1, 2], name='global_average_pooling', keepdims=True)\n",
    "              # 1x1 convolution with 256 filters( and batch normalization)\n",
    "              image_level_features = layers_lib.conv2d(image_level_features, depth, [1, 1], stride=1, scope='conv_1x1')\n",
    "              # bilinearly upsample features\n",
    "              image_level_features = tf.image.resize_bilinear(image_level_features, inputs_size, name='upsample')\n",
    "\n",
    "            net = tf.concat([conv_1x1, conv_3x3_1, conv_3x3_2, conv_3x3_3, image_level_features], axis=3, name='concat')\n",
    "            net = layers_lib.conv2d(net, depth, [1, 1], stride=1, scope='conv_1x1_concat')\n",
    "\n",
    "            return net\n",
    "\n",
    "\n",
    "def deeplab_v3_generator(num_classes,\n",
    "                         output_stride,\n",
    "                         base_architecture,\n",
    "                         pre_trained_model,\n",
    "                         batch_norm_decay,\n",
    "                         data_format='channels_last'):\n",
    "  \n",
    "      \"\"\"Generator for DeepLab v3 models.\n",
    "\n",
    "      Args:\n",
    "        num_classes: The number of possible classes for image classification.\n",
    "        output_stride: The ResNet unit's stride. Determines the rates for atrous convolution.\n",
    "          the rates are (6, 12, 18) when the stride is 16, and doubled when 8.\n",
    "        base_architecture: The architecture of base Resnet building block.\n",
    "        pre_trained_model: The path to the directory that contains pre-trained models.\n",
    "        batch_norm_decay: The moving average decay when estimating layer activation\n",
    "          statistics in batch normalization.\n",
    "        data_format: The input format ('channels_last', 'channels_first', or None).\n",
    "          If set to None, the format is dependent on whether a GPU is available.\n",
    "          Only 'channels_last' is supported currently.\n",
    "\n",
    "      Returns:\n",
    "        The model function that takes in `inputs` and `is_training` and\n",
    "        returns the output tensor of the DeepLab v3 model.\n",
    "      \"\"\"\n",
    "      if data_format is None:\n",
    "        # data_format = (\n",
    "        #     'channels_first' if tf.test.is_built_with_cuda() else 'channels_last')\n",
    "        pass\n",
    "\n",
    "      if batch_norm_decay is None:\n",
    "        batch_norm_decay = _BATCH_NORM_DECAY\n",
    "\n",
    "      if base_architecture not in ['resnet_v2_50', 'resnet_v2_101']:\n",
    "        raise ValueError(\"'base_architrecture' must be either 'resnet_v2_50' or 'resnet_v2_101'.\")\n",
    "\n",
    "      if base_architecture == 'resnet_v2_50':\n",
    "        base_model = resnet_v2.resnet_v2_50\n",
    "      else:\n",
    "        base_model = resnet_v2.resnet_v2_101\n",
    "\n",
    "      def model(inputs, is_training):\n",
    "        \"\"\"Constructs the ResNet model given the inputs.\"\"\"\n",
    "        if data_format == 'channels_first':\n",
    "          # Convert the inputs from channels_last (NHWC) to channels_first (NCHW).\n",
    "          # This provides a large performance boost on GPU. See\n",
    "          # https://www.tensorflow.org/performance/performance_guide#data_formats\n",
    "          inputs = tf.transpose(inputs, [0, 3, 1, 2])\n",
    "\n",
    "        # tf.logging.info('net shape: {}'.format(inputs.shape))\n",
    "\n",
    "        with tf.contrib.slim.arg_scope(resnet_v2.resnet_arg_scope(batch_norm_decay=batch_norm_decay)):\n",
    "          logits, end_points = base_model(inputs,\n",
    "                                          num_classes=None,\n",
    "                                          is_training=is_training,\n",
    "                                          global_pool=False,\n",
    "                                          output_stride=output_stride)\n",
    "\n",
    "        if is_training:\n",
    "          exclude = [base_architecture + '/logits', 'global_step']\n",
    "          variables_to_restore = tf.contrib.slim.get_variables_to_restore(exclude=exclude)\n",
    "          tf.train.init_from_checkpoint(pre_trained_model,\n",
    "                                        {v.name.split(':')[0]: v for v in variables_to_restore})\n",
    "\n",
    "        inputs_size = tf.shape(inputs)[1:3]\n",
    "        net = end_points[base_architecture + '/block4']\n",
    "        net = atrous_spatial_pyramid_pooling(net, output_stride, batch_norm_decay, is_training)\n",
    "        with tf.variable_scope(\"upsampling_logits\"):\n",
    "          net = layers_lib.conv2d(net, num_classes, [1, 1], activation_fn=None, normalizer_fn=None, scope='conv_1x1')\n",
    "          logits = tf.image.resize_bilinear(net, inputs_size, name='upsample')\n",
    "\n",
    "        return logits\n",
    "\n",
    "      return model\n",
    "\n",
    "def deeplabv3_model_fn(features, labels, mode, params):\n",
    "  images = tf.cast(features,tf.uint8)\n",
    "  #images = tf.cast(\n",
    "  #    tf.map_fn(preprocessing.mean_image_addition, features),\n",
    "  #    tf.uint8)\n",
    "\n",
    "  network = deeplab_v3_generator(params['num_classes'],\n",
    "                                 params['output_stride'],\n",
    "                                 params['base_architecture'],\n",
    "                                 params['pre_trained_model'],\n",
    "                                 params['batch_norm_decay'])\n",
    "    \n",
    "    \n",
    "  logits = network(features, mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  pred_classes = tf.expand_dims(tf.argmax(logits, axis=3, output_type=tf.int32), axis=3)\n",
    "\n",
    "  pred_decoded_labels = tf.py_func(preprocessing.decode_labels,\n",
    "                                   [pred_classes, params['batch_size'], params['num_classes']],\n",
    "                                   tf.uint8)\n",
    "\n",
    "  predictions = {\n",
    "      'classes': pred_classes,\n",
    "      'probabilities': tf.nn.softmax(logits, name='softmax_tensor'),\n",
    "      'decoded_labels': pred_decoded_labels,      \n",
    "  }\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    # Delete 'decoded_labels' from predictions because custom functions produce error when used with saved_model\n",
    "    predictions_without_decoded_labels = predictions.copy()\n",
    "    del predictions_without_decoded_labels['decoded_labels']\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(\n",
    "        mode=mode,\n",
    "        predictions=predictions,\n",
    "        export_outputs={\n",
    "            'preds': tf.estimator.export.PredictOutput(\n",
    "                predictions_without_decoded_labels)\n",
    "        })\n",
    "\n",
    "  gt_decoded_labels = tf.py_func(preprocessing.decode_labels,\n",
    "                                 [labels, params['batch_size'], params['num_classes']], tf.uint8)\n",
    "\n",
    "  labels = tf.squeeze(labels, axis=3)  # reduce the channel dimension.\n",
    "\n",
    "  logits_by_num_classes = tf.reshape(logits, [-1, params['num_classes']])\n",
    "  labels_flat = tf.reshape(labels, [-1, ])\n",
    "\n",
    "  valid_indices = tf.to_int32(labels_flat <= params['num_classes'] - 1)\n",
    "  valid_logits = tf.dynamic_partition(logits_by_num_classes, valid_indices, num_partitions=2)[1]\n",
    "  valid_labels = tf.dynamic_partition(labels_flat, valid_indices, num_partitions=2)[1]\n",
    "\n",
    "  preds_flat = tf.reshape(pred_classes, [-1, ])\n",
    "  valid_preds = tf.dynamic_partition(preds_flat, valid_indices, num_partitions=2)[1]\n",
    "  confusion_matrix = tf.confusion_matrix(valid_labels, valid_preds, num_classes=params['num_classes'])\n",
    "\n",
    "  predictions['valid_preds'] = valid_preds\n",
    "  predictions['valid_labels'] = valid_labels\n",
    "  predictions['confusion_matrix'] = confusion_matrix\n",
    "\n",
    "  cross_entropy = tf.losses.sparse_softmax_cross_entropy(\n",
    "      logits=valid_logits, labels=valid_labels)\n",
    "\n",
    "  # Create a tensor named cross_entropy for logging purposes.\n",
    "  tf.identity(cross_entropy, name='cross_entropy')\n",
    "  tf.summary.scalar('cross_entropy', cross_entropy)\n",
    "\n",
    "  if not params['freeze_batch_norm']:\n",
    "    train_var_list = [v for v in tf.trainable_variables()]\n",
    "  else:\n",
    "    train_var_list = [v for v in tf.trainable_variables()\n",
    "                      if 'beta' not in v.name and 'gamma' not in v.name]\n",
    "\n",
    "  # Add weight decay to the loss.\n",
    "  with tf.variable_scope(\"total_loss\"):\n",
    "    loss = cross_entropy + params.get('weight_decay', _WEIGHT_DECAY) * tf.add_n(\n",
    "        [tf.nn.l2_loss(v) for v in train_var_list])\n",
    "  # loss = tf.losses.get_total_loss()  # obtain the regularization losses as well\n",
    "\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    tf.summary.image('images',\n",
    "                     tf.concat(axis=2, values=[images, gt_decoded_labels, pred_decoded_labels]),\n",
    "                     max_outputs=params['tensorboard_images_max_outputs'])  # Concatenate row-wise.\n",
    "\n",
    "\n",
    "    global_step = tf.train.get_or_create_global_step()\n",
    "\n",
    "    if params['learning_rate_policy'] == 'piecewise':\n",
    "      # Scale the learning rate linearly with the batch size. When the batch size\n",
    "      # is 128, the learning rate should be 0.1.\n",
    "      initial_learning_rate = 0.1 * params['batch_size'] / 128\n",
    "      batches_per_epoch = params['num_train'] / params['batch_size']\n",
    "      # Multiply the learning rate by 0.1 at 100, 150, and 200 epochs.\n",
    "      boundaries = [int(batches_per_epoch * epoch) for epoch in [100, 150, 200]]\n",
    "      values = [initial_learning_rate * decay for decay in [1, 0.1, 0.01, 0.001]]\n",
    "      learning_rate = tf.train.piecewise_constant(\n",
    "          tf.cast(global_step, tf.int32), boundaries, values)\n",
    "    elif params['learning_rate_policy'] == 'poly':\n",
    "      learning_rate = tf.train.polynomial_decay(\n",
    "          params['initial_learning_rate'],\n",
    "          tf.cast(global_step, tf.int32) - params['initial_global_step'],\n",
    "          params['max_iter'], params['end_learning_rate'], power=params['power'])\n",
    "    else:\n",
    "      raise ValueError('Learning rate policy must be \"piecewise\" or \"poly\"')\n",
    "\n",
    "    # Create a tensor named learning_rate for logging purposes\n",
    "    tf.identity(learning_rate, name='learning_rate')\n",
    "    tf.summary.scalar('learning_rate', learning_rate)\n",
    "\n",
    "    optimizer = tf.train.MomentumOptimizer(\n",
    "        learning_rate=learning_rate,\n",
    "        momentum=params['momentum'])\n",
    "\n",
    "    # Batch norm requires update ops to be added as a dependency to the train_op\n",
    "    update_ops = tf.get_collection(tf.GraphKeys.UPDATE_OPS)\n",
    "    with tf.control_dependencies(update_ops):\n",
    "      train_op = optimizer.minimize(loss, global_step, var_list=train_var_list)\n",
    "  else:\n",
    "    train_op = None\n",
    "\n",
    "  accuracy = tf.metrics.accuracy(\n",
    "      valid_labels, valid_preds)\n",
    "  mean_iou = tf.metrics.mean_iou(valid_labels, valid_preds, params['num_classes'])\n",
    "  metrics = {'px_accuracy': accuracy, 'mean_iou': mean_iou}\n",
    "\n",
    "  # Create a tensor named train_accuracy for logging purposes\n",
    "  tf.identity(accuracy[1], name='train_px_accuracy')\n",
    "  tf.summary.scalar('train_px_accuracy', accuracy[1])\n",
    "\n",
    "  def compute_mean_iou(total_cm, name='mean_iou'):\n",
    "    \"\"\"Compute the mean intersection-over-union via the confusion matrix.\"\"\"\n",
    "    sum_over_row = tf.to_float(tf.reduce_sum(total_cm, 0))\n",
    "    sum_over_col = tf.to_float(tf.reduce_sum(total_cm, 1))\n",
    "    cm_diag = tf.to_float(tf.diag_part(total_cm))\n",
    "    denominator = sum_over_row + sum_over_col - cm_diag\n",
    "\n",
    "    # The mean is only computed over classes that appear in the\n",
    "    # label or prediction tensor. If the denominator is 0, we need to\n",
    "    # ignore the class.\n",
    "    num_valid_entries = tf.reduce_sum(tf.cast(\n",
    "        tf.not_equal(denominator, 0), dtype=tf.float32))\n",
    "\n",
    "    # If the value of the denominator is 0, set it to 1 to avoid\n",
    "    # zero division.\n",
    "    denominator = tf.where(\n",
    "        tf.greater(denominator, 0),\n",
    "        denominator,\n",
    "        tf.ones_like(denominator))\n",
    "    iou = tf.div(cm_diag, denominator)\n",
    "\n",
    "    for i in range(params['num_classes']):\n",
    "      tf.identity(iou[i], name='train_iou_class{}'.format(i))\n",
    "      tf.summary.scalar('train_iou_class{}'.format(i), iou[i])\n",
    "\n",
    "    # If the number of valid entries is 0 (no classes) we return 0.\n",
    "    result = tf.where(\n",
    "        tf.greater(num_valid_entries, 0),\n",
    "        tf.reduce_sum(iou, name=name) / num_valid_entries,\n",
    "        0)\n",
    "    return result\n",
    "\n",
    "  train_mean_iou = compute_mean_iou(mean_iou[1])\n",
    "\n",
    "  tf.identity(train_mean_iou, name='train_mean_iou')\n",
    "  tf.summary.scalar('train_mean_iou', train_mean_iou)\n",
    "\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode,\n",
    "      predictions=predictions,\n",
    "      loss=loss,\n",
    "      train_op=train_op,\n",
    "eval_metric_ops=metrics)\n",
    "\n",
    "def generator():\n",
    "    while True:\n",
    "        batch_nums = TOTAL_SIZE\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        \n",
    "        for index in batch_nums:\n",
    "            x_data, y_data = ImportBatch(getData(1, index, 0, type='train', SCALE_RATE)\n",
    "            x_data=np.squeeze(x_data)\n",
    "            y_data=np.squeeze(y_data)\n",
    "            y_data=np.expand_dims(y_train_data,axis=3)            \n",
    "            x_data = x_data.astype('float32')\n",
    "            y_data=y_data.astype('float32')\n",
    "            batch_input.append(x_data)\n",
    "            batch_output.append(y_data)\n",
    "            \n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)        \n",
    "        yield batch_x, batch_y\n",
    "        \n",
    "def input_fn(is_training, dataset, batch_size, num_epochs=1):\n",
    "    \"\"\" Input_fn using the tf.data input pipeline for CIFAR-10 dataset.\n",
    "  Args:\n",
    "    is_training: A boolean denoting whether the input is for training.\n",
    "    data_dir: The directory containing the input data.\n",
    "    batch_size: The number of samples per batch.\n",
    "    num_epochs: The number of epochs to repeat the dataset.\n",
    "  Returns:\n",
    "    A tuple of images and labels.\n",
    "  \"\"\"\n",
    "\n",
    "\n",
    "    #iterator = dataset.make_one_shot_iterator()\n",
    "    images, labels = dataset.get_next()\n",
    "    return images, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "#with tf.device(\"/gpu:2\"):\n",
    "#    tf.app.run()\n",
    "\n",
    "with tf.device('/GPU:2'):\n",
    "    session_config=tf.ConfigProto(device_count={'GPU': 4})\n",
    "    # Set up a RunConfig to only save checkpoints once per training cycle.\n",
    "    run_config = tf.estimator.RunConfig().replace(save_checkpoints_steps=200)\n",
    "    \n",
    "    model = tf.estimator.Estimator(\n",
    "        model_fn=deeplabv3_model_fn,\n",
    "        config=run_config,\n",
    "        model_dir='home/rvygon/SiriusCV/deeplab',\n",
    "        params = {\n",
    "            'output_stride': 8,\n",
    "            'batch_size': BATCH_SIZE,\n",
    "            'base_architecture': 'resnet_v2_101',\n",
    "            'pre_trained_model': '/home/rvygon/data/DeepLab/resnet_v2_101.ckpt',\n",
    "            'batch_norm_decay': _BATCH_NORM_DECAY,\n",
    "            'num_classes': _NUM_CLASSES,\n",
    "            'tensorboard_images_max_outputs': 6,\n",
    "            'weight_decay': 2e-4,\n",
    "            'learning_rate_policy': 'poly',\n",
    "            'num_train': 200,\n",
    "            'initial_learning_rate': 7e-3,\n",
    "            'max_iter': 30000,\n",
    "            'end_learning_rate': 1e-6,\n",
    "            'power': _POWER,\n",
    "            'momentum': _MOMENTUM,\n",
    "            'freeze_batch_norm': False,\n",
    "            'initial_global_step': 0\n",
    "          })\n",
    "\n",
    "    for _ in range(150):\n",
    "        tensors_to_log = {\n",
    "        'learning_rate': 'learning_rate',\n",
    "        'cross_entropy': 'cross_entropy',\n",
    "        'train_px_accuracy': 'train_px_accuracy',\n",
    "        'train_mean_iou': 'train_mean_iou',\n",
    "      }\n",
    "        x_train_data, y_train_data = importRandomBatch(TOTAL_SIZE,'train', SCALE_RATE)\n",
    "        x_train_data = x_train_data.astype('float32')\n",
    "        y_train_data = y_train_data.astype('int32')\n",
    "        y_train_data=np.expand_dims(y_train_data,axis=3)\n",
    "        dataset = tf.data.Dataset.from_tensor_slices((x_train_data, y_train_data))\n",
    "\n",
    "\n",
    "        dataset = dataset.repeat().batch(BATCH_SIZE)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        logging_hook = tf.train.LoggingTensorHook(\n",
    "          tensors=tensors_to_log, every_n_iter=10)\n",
    "        train_hooks = [logging_hook]\n",
    "        eval_hooks = None\n",
    "\n",
    "\n",
    "        tf.logging.info(\"Start training.\")\n",
    "        model.train(\n",
    "          input_fn=lambda: input_fn(True, dataset, BATCH_SIZE, EPOCHS_PER_EVAL),\n",
    "          hooks=train_hooks,\n",
    "          steps=202  # For debug\n",
    "        )\n",
    "\n",
    "        tf.logging.info(\"Start evaluation.\")\n",
    "        # Evaluate the model and print results\n",
    "    \"\"\"eval_results = model.evaluate(\n",
    "        # Batch size must be 1 for testing because the images' size differs\n",
    "        input_fn=lambda: input_fn(False, dataset, 1),\n",
    "        hooks=eval_hooks,\n",
    "        # steps=1  # For debug\n",
    "        )\n",
    "    print(eval_results)\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'home/rvygon/SiriusCV/deeplab', '_tf_random_seed': None, '_save_summary_steps': 100, '_save_checkpoints_steps': None, '_save_checkpoints_secs': 600, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7fbadf388cf8>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n"
     ]
    }
   ],
   "source": [
    " os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1'\n",
    "\n",
    "  \n",
    "if False:\n",
    "    debug_hook = tf_debug.LocalCLIDebugHook()\n",
    "    pred_hooks = [debug_hook]\n",
    "\n",
    "model = tf.estimator.Estimator(\n",
    "  model_fn=deeplabv3_model_fn,\n",
    "  model_dir='home/rvygon/SiriusCV/deeplab',\n",
    "  params={\n",
    "      'output_stride': 8,\n",
    "      'batch_size': 1,  # Batch size must be 1 because the images' size may differ\n",
    "      'base_architecture': 'resnet_v2_101',\n",
    "      'pre_trained_model': None,\n",
    "      'batch_norm_decay': None,\n",
    "      'num_classes': _NUM_CLASSES,\n",
    "  })\n",
    "dataset = tf.data.Dataset.from_generator(generator=_generator,\n",
    "                                         output_types=(tf.float32, tf.float32),\n",
    "                                         output_shapes=shapes)\n",
    "\n",
    "\n",
    "\n",
    "dataset = dataset.repeat().batch(1)\n",
    "\n",
    "predictions = model.predict(\n",
    "    input_fn=lambda: input_fn(False, dataset, BATCH_SIZE, EPOCHS_PER_EVAL),\n",
    "    #hooks=pred_hooks\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred1 = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Variable conv_1x1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 252, in variable\n    use_resource=use_resource)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 297, in model_variable\n    use_resource=use_resource)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-018b90a46a92>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mVAL_SIZE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mpred1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, input_fn, predict_keys, hooks, checkpoint_path, yield_single_examples)\u001b[0m\n\u001b[1;32m    541\u001b[0m             input_fn, model_fn_lib.ModeKeys.PREDICT)\n\u001b[1;32m    542\u001b[0m         estimator_spec = self._call_model_fn(\n\u001b[0;32m--> 543\u001b[0;31m             features, None, model_fn_lib.ModeKeys.PREDICT, self.config)\n\u001b[0m\u001b[1;32m    544\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    545\u001b[0m         \u001b[0;31m# Call to warm_start has to be after model_fn is called.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/estimator/estimator.py\u001b[0m in \u001b[0;36m_call_model_fn\u001b[0;34m(self, features, labels, mode, config)\u001b[0m\n\u001b[1;32m   1131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1132\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1133\u001b[0;31m     \u001b[0mmodel_fn_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_model_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1134\u001b[0m     \u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Done calling model_fn.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dbfba6083632>\u001b[0m in \u001b[0;36mdeeplabv3_model_fn\u001b[0;34m(features, labels, mode, params)\u001b[0m\n\u001b[1;32m    186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    187\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 188\u001b[0;31m   \u001b[0mlogits\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnetwork\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmode\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m   \u001b[0mpred_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexpand_dims\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dbfba6083632>\u001b[0m in \u001b[0;36mmodel\u001b[0;34m(inputs, is_training)\u001b[0m\n\u001b[1;32m    164\u001b[0m         \u001b[0minputs_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_points\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbase_architecture\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'/block4'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 166\u001b[0;31m         \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0matrous_spatial_pyramid_pooling\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_stride\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_norm_decay\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_training\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    167\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvariable_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"upsampling_logits\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m           \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnormalizer_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_1x1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-dbfba6083632>\u001b[0m in \u001b[0;36matrous_spatial_pyramid_pooling\u001b[0;34m(inputs, output_stride, batch_norm_decay, is_training, depth)\u001b[0m\n\u001b[1;32m     88\u001b[0m               \u001b[0mimage_level_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'global_average_pooling'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     89\u001b[0m               \u001b[0;31m# 1x1 convolution with 256 filters( and batch normalization)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 90\u001b[0;31m               \u001b[0mimage_level_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayers_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconv2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_level_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdepth\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstride\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'conv_1x1'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     91\u001b[0m               \u001b[0;31m# bilinearly upsample features\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     92\u001b[0m               \u001b[0mimage_level_features\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresize_bilinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_level_features\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'upsample'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution2d\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope)\u001b[0m\n\u001b[1;32m   1152\u001b[0m                      \u001b[0mtrainable\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1153\u001b[0m                      \u001b[0mscope\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1154\u001b[0;31m                      conv_dims=2)\n\u001b[0m\u001b[1;32m   1155\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1156\u001b[0m \u001b[0mconvolution2d\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolution\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__doc__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mconvolution\u001b[0;34m(inputs, num_outputs, kernel_size, stride, padding, data_format, rate, activation_fn, normalizer_fn, normalizer_params, weights_initializer, weights_regularizer, biases_initializer, biases_regularizer, reuse, variables_collections, outputs_collections, trainable, scope, conv_dims)\u001b[0m\n\u001b[1;32m   1055\u001b[0m         \u001b[0m_scope\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m         _reuse=reuse)\n\u001b[0;32m-> 1057\u001b[0;31m     \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlayer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mapply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1058\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1059\u001b[0m     \u001b[0;31m# Add variables to collections.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36mapply\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    803\u001b[0m       \u001b[0mOutput\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    804\u001b[0m     \"\"\"\n\u001b[0;32m--> 805\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    806\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    807\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_set_learning_phase_metadata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    360\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    361\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecuting_eagerly\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'shape'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minput_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m           \u001b[0minput_shapes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_shapes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    729\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuilt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/layers/convolutional.py\u001b[0m in \u001b[0;36mbuild\u001b[0;34m(self, input_shape)\u001b[0m\n\u001b[1;32m    159\u001b[0m         \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel_constraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0mtrainable\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 161\u001b[0;31m         dtype=self.dtype)\n\u001b[0m\u001b[1;32m    162\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muse_bias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m       self.bias = self.add_weight(\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/layers/base.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, use_resource, synchronization, aggregation, partitioner)\u001b[0m\n\u001b[1;32m    274\u001b[0m             \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    275\u001b[0m             \u001b[0maggregation\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0maggregation\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 276\u001b[0;31m             getter=vs.get_variable)\n\u001b[0m\u001b[1;32m    277\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    278\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36madd_weight\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, trainable, constraint, partitioner, use_resource, synchronization, aggregation, getter)\u001b[0m\n\u001b[1;32m    563\u001b[0m         \u001b[0muse_resource\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_resource\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m         \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 565\u001b[0;31m         aggregation=aggregation)\n\u001b[0m\u001b[1;32m    566\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    567\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mregularizer\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_add_variable_with_custom_getter\u001b[0;34m(self, name, shape, dtype, initializer, getter, overwrite, **kwargs_for_getter)\u001b[0m\n\u001b[1;32m    533\u001b[0m     new_variable = getter(\n\u001b[1;32m    534\u001b[0m         \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitializer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitializer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         **kwargs_for_getter)\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;31m# If we set an initializer and the variable processed it, tracking will not\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1465\u001b[0m       \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1466\u001b[0m       \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1467\u001b[0;31m       aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1469\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, var_store, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m   1215\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m   1218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m   def _get_partitioned_variable(self,\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36mget_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, custom_getter, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    508\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m\"constraint\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfunction_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    509\u001b[0m         \u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"constraint\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstraint\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 510\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mcustom_getter_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    511\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    512\u001b[0m       return _true_getter(\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36mlayer_variable_getter\u001b[0;34m(getter, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1742\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1743\u001b[0m     \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rename'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrename\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1744\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_model_variable_getter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1745\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mlayer_variable_getter\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/layers/python/layers/layers.py\u001b[0m in \u001b[0;36m_model_variable_getter\u001b[0;34m(getter, name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, partitioner, rename, use_resource, **_)\u001b[0m\n\u001b[1;32m   1733\u001b[0m       \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1734\u001b[0m       \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgetter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1735\u001b[0;31m       use_resource=use_resource)\n\u001b[0m\u001b[1;32m   1736\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mmodel_variable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    295\u001b[0m                  \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    296\u001b[0m                  \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcustom_getter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_getter\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 297\u001b[0;31m                  use_resource=use_resource)\n\u001b[0m\u001b[1;32m    298\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mvar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    299\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\u001b[0m in \u001b[0;36mfunc_with_args\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    181\u001b[0m       \u001b[0mcurrent_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcurrent_scope\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey_func\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    182\u001b[0m       \u001b[0mcurrent_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 183\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mcurrent_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    184\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    185\u001b[0m   \u001b[0m_add_op\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\u001b[0m in \u001b[0;36mvariable\u001b[0;34m(name, shape, dtype, initializer, regularizer, trainable, collections, caching_device, device, partitioner, custom_getter, use_resource)\u001b[0m\n\u001b[1;32m    250\u001b[0m                   \u001b[0mcaching_device\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcaching_device\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m                   \u001b[0mpartitioner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpartitioner\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m                   use_resource=use_resource)\n\u001b[0m\u001b[1;32m    253\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_true_getter\u001b[0;34m(name, shape, dtype, initializer, regularizer, reuse, trainable, collections, caching_device, partitioner, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    479\u001b[0m           \u001b[0mconstraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconstraint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    480\u001b[0m           \u001b[0msynchronization\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msynchronization\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 481\u001b[0;31m           aggregation=aggregation)\n\u001b[0m\u001b[1;32m    482\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    483\u001b[0m     \u001b[0;31m# Set trainable value based on synchronization value.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/variable_scope.py\u001b[0m in \u001b[0;36m_get_single_variable\u001b[0;34m(self, name, shape, dtype, initializer, regularizer, partition_info, reuse, trainable, collections, caching_device, validate_shape, use_resource, constraint, synchronization, aggregation)\u001b[0m\n\u001b[1;32m    846\u001b[0m                          \u001b[0;34m\"reuse=tf.AUTO_REUSE in VarScope? \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m                          \"Originally defined at:\\n\\n%s\" % (\n\u001b[0;32m--> 848\u001b[0;31m                              name, \"\".join(traceback.format_list(tb))))\n\u001b[0m\u001b[1;32m    849\u001b[0m       \u001b[0mfound_var\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vars\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mshape\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_compatible_with\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfound_var\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Variable conv_1x1/weights already exists, disallowed. Did you mean to set reuse=True or reuse=tf.AUTO_REUSE in VarScope? Originally defined at:\n\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 252, in variable\n    use_resource=use_resource)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/arg_scope.py\", line 183, in func_with_args\n    return func(*args, **current_args)\n  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/contrib/framework/python/ops/variables.py\", line 297, in model_variable\n    use_resource=use_resource)\n"
     ]
    }
   ],
   "source": [
    "for i in range(VAL_SIZE):\n",
    "    pred1.append(next(predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(pred1))\n",
    "imshow(pred1[0]['decoded_labels'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    colorImage(x_val_data[i],np.squeeze(pred1[i]['classes']),'classes.txt','colors.txt','encoded/res'+str(i+100)+'.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
