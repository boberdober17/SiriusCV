{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CITYSCAPES_DATASET=/home/rvygon/data/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n",
      "1.12.0\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.backend' has no attribute '__version__'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-11b7bfb6eab3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'autoreload 2'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m: module 'keras.backend' has no attribute '__version__'"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "from skimage.io import imread, imshow, imsave\n",
    "\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "import time\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "%env CITYSCAPES_DATASET = /home/rvygon/data/\n",
    "tf.device('/device:GPU:1')\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell once\n",
    "#%run  cityscapesscripts/preparation/createTrainIdLabelImgs\n",
    "def upd_print(str):\n",
    "            sys.stdout.write('\\r')       \n",
    "            sys.stdout.write(str)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#x_train_data, y_train_data = getData(300,0,'train')\n",
    "x_val, y_val, files = importBatch(1,0,1,'val',scale = 4)\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "def preprocess_pic(X, y):    \n",
    "    y=to_categorical(y)\n",
    "    return X, y\n",
    "\n",
    "def keras_generator(batch_size,scale):\n",
    "    while True:\n",
    "        batch_nums = np.random.randint(low=1000, high=2000, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        \n",
    "        for index in batch_nums:\n",
    "            input_labels, input_images = getData(1, index,type='train')\n",
    "            input_image = input_images[0]\n",
    "            input_label = input_labels[0]           \n",
    "            \n",
    "            X_img = imread(input_image)\n",
    "            if (scale != 0):\n",
    "                X_new = np.zeros((int(X_img.shape[0] / scale), int(X_img.shape[1] / scale),3))\n",
    "                k = 0\n",
    "                for x in X_img[::scale]:\n",
    "                    X_new[k]=x[::scale]\n",
    "                    k+=1\n",
    "                X_img = X_new\n",
    "            y_img = imread(input_label)\n",
    "            if (scale != 0):\n",
    "                y_new = np.zeros((int(y_img.shape[0] / scale), int(y_img.shape[1] / scale)))\n",
    "                k = 0\n",
    "                for y in y_img[::scale]:\n",
    "                    y_new[k] = y[::scale]\n",
    "                    k += 1\n",
    "                y_img = y_new\n",
    "            \n",
    "            X_img, y_img = preprocess_pic(X_img, y_img)\n",
    "            \n",
    "            batch_input.append(X_img)\n",
    "            batch_output.append(y_img)\n",
    "            \n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)        \n",
    "        yield batch_x, batch_y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/decorator_utils.py:127: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "WARNING:tensorflow:From /opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/util/decorator_utils.py:127: GraphKeys.VARIABLES (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.GraphKeys.GLOBAL_VARIABLES` instead.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n",
      "WARNING:tensorflow:VARIABLES collection name is deprecated, please use GLOBAL_VARIABLES instead; VARIABLES will be removed after 2017-03-02.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of numpy.lib failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "NameError: name 'type_check' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.index_tricks failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module 'numpy' has no attribute 'matrixlib'\n",
      "]\n",
      "[autoreload of numpy.matrixlib failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "NameError: name 'defmatrix' is not defined\n",
      "]\n",
      "[autoreload of numpy.lib.scimath failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module 'numpy.core' has no attribute 'numerictypes'\n",
      "]\n",
      "[autoreload of numpy.ma.core failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module 'numpy.core' has no attribute 'numerictypes'\n",
      "]\n",
      "Using TensorFlow backend.\n",
      "[autoreload of tensorflow failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ImportError: cannot import name 'Activation'\n",
      "]\n",
      "[autoreload of tensorflow.python failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "tensorflow.python.util.tf_export.SymbolAlreadyExposedError: Symbol AttrValue is already exposed as ('AttrValue',).\n",
      "]\n",
      "[autoreload of tensorflow.python.pywrap_tensorflow_internal failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module '_pywrap_tensorflow_internal' has no attribute 'TFE_ContextOptionsSetServerDef'\n",
      "]\n",
      "[autoreload of tensorflow.core.protobuf.config_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/core/protobuf/config.proto\":\n",
      "  tensorflow/core/protobuf/config.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of tensorflow.core.framework.step_stats_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/core/framework/step_stats.proto\":\n",
      "  tensorflow/core/framework/step_stats.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of tensorflow.core.protobuf.debug_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/core/protobuf/debug.proto\":\n",
      "  tensorflow/core/protobuf/debug.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of tensorflow.core.protobuf.rewriter_config_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/core/protobuf/rewriter_config.proto\":\n",
      "  tensorflow/core/protobuf/rewriter_config.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of tensorflow.python.framework.sparse_tensor failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module 'tensorflow.python.pywrap_tensorflow' has no attribute 'RegisterSparseTensorValueClass'\n",
      "]\n",
      "[autoreload of tensorflow.python.util.nest failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: module 'tensorflow.python.pywrap_tensorflow' has no attribute 'RegisterSequenceClass'\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.resource_variable_ops failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "AttributeError: type object 'Tensor' has no attribute '__xor__'\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.math_ops failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: operator __div__ cannot be overwritten again on class <class 'tensorflow.python.framework.sparse_tensor.SparseTensor'>.\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.variable_scope failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.sparse_ops failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: sparse_reduce_max() requires a code object with 10 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.logging_ops failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: Print() requires a code object with 4 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.eager.backprop failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: __new__() got an unexpected keyword argument 'tensor_id'\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.io_ops failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 4 free vars, not 1\n",
      "]\n",
      "[autoreload of tensorflow.python.training.checkpoint_state_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/python/training/checkpoint_state.proto\":\n",
      "  tensorflow/python/training/checkpoint_state.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n",
      "[autoreload of tensorflow.python.training.distribute failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: increment_var() requires a code object with 4 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.platform.gfile failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 4 free vars, not 1\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.engine.base_layer failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "RecursionError: maximum recursion depth exceeded\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.initializers failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.engine.network failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: compute_output_shape() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.layers.convolutional failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: call() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.layers.core failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: wrapper() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.engine.sequential failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: layers() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.keras.preprocessing.image failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 1 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.estimator.estimator failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "tensorflow.python.util.tf_export.SymbolAlreadyExposedError: Symbol VocabInfo is already exposed as ('estimator.VocabInfo',).\n",
      "]\n",
      "[autoreload of tensorflow.python.training.queue_runner_impl failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 4 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.training.training failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "tensorflow.python.util.tf_export.SymbolAlreadyExposedError: Symbol BytesList is already exposed as ('train.BytesList',).\n",
      "]\n",
      "[autoreload of tensorflow.python.training.input failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: limit_epochs() requires a code object with 4 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.python.saved_model.builder_impl failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: add_meta_graph() requires a code object with 10 free vars, not 0\n",
      "]\n",
      "[autoreload of tensorflow.core.kernels.boosted_trees.boosted_trees_pb2 failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "TypeError: Couldn't build proto file into descriptor pool!\n",
      "Invalid proto descriptor for file \"tensorflow/core/kernels/boosted_trees/boosted_trees.proto\":\n",
      "  tensorflow/core/kernels/boosted_trees/boosted_trees.proto: A file with this name is already in the pool.\n",
      "\n",
      "]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of tensorflow.python.ops.distributions.exponential failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "IndexError: list index out of range\n",
      "]\n",
      "[autoreload of tensorflow.python.profiler.profiler failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "tensorflow.python.util.tf_export.SymbolAlreadyExposedError: Symbol GraphNodeProto is already exposed as ('profiler.GraphNodeProto',).\n",
      "]\n",
      "[autoreload of tensorflow.python.platform.test failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "tensorflow.python.util.tf_export.SymbolAlreadyExposedError: Symbol unittest.mock is already exposed as ('test.mock',).\n",
      "]\n",
      "[autoreload of tensorflow.python.ops.rnn_cell_impl failed: Traceback (most recent call last):\n",
      "  File \"/opt/conda/anaconda3/lib/python3.6/site-packages/IPython/extensions/autoreload.py\", line 247, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "ValueError: __init__() requires a code object with 4 free vars, not 1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "#UNET https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "def unet(pretrained_weights = None,input_size = (256,512,3)):\n",
    "    inputs = Input(input_size)\n",
    "  \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)    \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))#drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(20, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy', 'mean_iou'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "\n",
    "model = unet()\n",
    "generator = keras_generator(1,4)\n",
    "model_checkpoint = ModelCheckpoint('unet_RV1.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "history = model.fit_generator(generator,steps_per_epoch=3000,epochs=50,callbacks=[model_checkpoint, csv_logger], validation_data=(x_val,y_val),validation_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "\n",
    "#create model\n",
    "model = Sequential()\n",
    "\n",
    "#add model layers\n",
    "model.add(Conv2D(64, kernel_size=3, activation='relu', input_shape=(28,28,1)))\n",
    "model.add(Conv2D(32, kernel_size=3, activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "SCALE = 4\n",
    "#tic = time.time()\n",
    "#x_val, y_val, filenames = importBatch(500,0,0,'val',SCALE)\n",
    "#toc = time.time()\n",
    "#print('Load validation batch:', toc - tic)\n",
    "def eval_model(model):          \n",
    "        \n",
    "        x_pred = model.predict(x_val,verbose=1)        \n",
    "        new_x=np.argmax(x_pred,axis=3)\n",
    "        \n",
    "        \"\"\" UPSCALING\n",
    "        new_new_x = np.zeros((new_x.shape[0],new_x.shape[1]*SCALE,new_x.shape[2]*SCALE))\n",
    "        \n",
    "        for i in range(x_pred.shape[0]):\n",
    "            new_new_x[i]=UpscaleImg(new_x[i],SCALE,0)\n",
    "            upd_print((\"Upscaled %d images\" % i))\n",
    "        print()\n",
    "        new_new_x=new_new_x.astype(int)\"\"\"\n",
    "        \n",
    "        new_x=new_x.astype(int)        \n",
    "        \n",
    "        \"\"\"   SAVE\n",
    "        cityscapesPath = os.environ['CITYSCAPES_DATASET']        \n",
    "        for i in range(len(filenames)):\n",
    "            impath = os.path.join(cityscapesPath,'results', filenames[i].split('/')[7]+'.png')           \n",
    "            imsave(impath, new_new_x[i])\n",
    "            upd_print(\"Saved %d images\" % i)            \n",
    "        print()\n",
    "        toc = time.time()\n",
    "        print('Save files:', toc -tic) \"\"\"\n",
    "        \n",
    "        score = eval_preds(new_x,y_val)        \n",
    "        return score\n",
    "\n",
    "model = load_model('unet_RV1.hdf5')\n",
    "print(eval_model(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "super(type, obj): obj must be an instance or subtype of type",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-d1d2d64c1de1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-d1d2d64c1de1>\u001b[0m in \u001b[0;36mnet\u001b[0;34m(input_size)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mconv1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mConv2D\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mactivation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'relu'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpadding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'same'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkernel_initializer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'he_normal'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconv1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/layers/convolutional.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, filters, kernel_size, strides, padding, data_format, dilation_rate, activation, use_bias, kernel_initializer, bias_initializer, kernel_regularizer, bias_regularizer, activity_regularizer, kernel_constraint, bias_constraint, **kwargs)\u001b[0m\n\u001b[1;32m    471\u001b[0m                  \u001b[0mbias_constraint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    472\u001b[0m                  **kwargs):\n\u001b[0;32m--> 473\u001b[0;31m         super(Conv2D, self).__init__(\n\u001b[0m\u001b[1;32m    474\u001b[0m             \u001b[0mrank\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    475\u001b[0m             \u001b[0mfilters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfilters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: super(type, obj): obj must be an instance or subtype of type"
     ]
    }
   ],
   "source": [
    "#UNET https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "inp = np.zeros((1,1,1,1))\n",
    "out = np.zeros((1,1,1,8))\n",
    "out[0][0]=1\n",
    "def net(input_size = (1,1,1)):\n",
    "    inputs = Input(input_size)\n",
    "  \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)    \n",
    "    \n",
    "    model = Model(input = inputs, output = conv1)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "model = net()\n",
    "model.fit(inp,out,epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
