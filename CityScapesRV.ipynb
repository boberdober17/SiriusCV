{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CITYSCAPES_DATASET=/home/rvygon/data/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import h5py\n",
    "%matplotlib inline\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from keras.models import *\n",
    "from keras.layers import *\n",
    "from keras.optimizers import *\n",
    "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "from keras import backend as keras\n",
    "\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "%env CITYSCAPES_DATASET = /home/rvygon/data/\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run this cell once\n",
    "#%run  cityscapesscripts/preparation/createTrainIdLabelImgs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000e+00 4.77296e+05]\n",
      " [1.00000e+00 4.53860e+04]\n",
      " [2.00000e+00 2.61651e+05]\n",
      " [4.00000e+00 2.86800e+03]\n",
      " [5.00000e+00 1.68800e+04]\n",
      " [6.00000e+00 2.91100e+03]\n",
      " [7.00000e+00 4.95100e+03]\n",
      " [8.00000e+00 1.46077e+05]\n",
      " [9.00000e+00 2.42000e+02]\n",
      " [1.00000e+01 4.27310e+04]\n",
      " [1.10000e+01 4.03400e+03]\n",
      " [1.20000e+01 1.80800e+03]\n",
      " [1.30000e+01 1.23560e+05]\n",
      " [1.40000e+01 1.27100e+03]\n",
      " [1.50000e+01 4.87600e+03]\n",
      " [1.60000e+01 1.41200e+03]\n",
      " [1.70000e+01 1.24000e+03]\n",
      " [1.80000e+01 2.58500e+03]\n",
      " [1.90000e+01 1.68941e+05]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 256, 512, 20)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_val, y_val,files = importBatch(10,0,0,'val',scale = 4)\n",
    "from keras.utils import to_categorical\n",
    "#y_val[y_val==255]=19\n",
    "unique, counts = np.unique(y_val, return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)\n",
    "y_val = to_categorical(y_val)\n",
    "y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def preprocess_pic(X, y):    \n",
    "    y=to_categorical(y)\n",
    "    return X, y\n",
    "\n",
    "def keras_generator(batch_size,scale):\n",
    "    while True:\n",
    "        batch_nums = np.random.randint(low=1000, high=2000, size=batch_size)\n",
    "        batch_input = []\n",
    "        batch_output = []\n",
    "        \n",
    "        for index in batch_nums:\n",
    "            input_labels, input_images = getData(1, index,type='train')\n",
    "            input_image = input_images[0]\n",
    "            input_label = input_labels[0]           \n",
    "            \n",
    "            X_img = imread(input_image)\n",
    "            if (scale != 0):\n",
    "                X_new = np.zeros((int(X_img.shape[0] / scale), int(X_img.shape[1] / scale),3))\n",
    "                k = 0\n",
    "                for x in X_img[::scale]:\n",
    "                    X_new[k]=x[::scale]\n",
    "                    k+=1\n",
    "                X_img = X_new\n",
    "            y_img = imread(input_label)\n",
    "            if (scale != 0):\n",
    "                y_new = np.zeros((int(y_img.shape[0] / scale), int(y_img.shape[1] / scale)))\n",
    "                k = 0\n",
    "                for y in y_img[::scale]:\n",
    "                    y_new[k] = y[::scale]\n",
    "                    k += 1\n",
    "                y_img = y_new\n",
    "            \n",
    "            X_img, y_img = preprocess_pic(X_img, y_img)\n",
    "            \n",
    "            batch_input.append(X_img)\n",
    "            batch_output.append(y_img)\n",
    "            \n",
    "        batch_x = np.array(batch_input)\n",
    "        batch_y = np.array(batch_output)        \n",
    "        yield batch_x, batch_y\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNET https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "def unet(pretrained_weights = None,input_size = (256,512,3)):\n",
    "    inputs = Input(input_size)\n",
    "  \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)    \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))#drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(20, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model(input = inputs, output = conv10)\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "    \n",
    "    #model.summary()\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:45: UserWarning: Update your `Model` call to the Keras 2 API: `Model(inputs=Tensor(\"in..., outputs=Tensor(\"co...)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "  73/1500 [>.............................] - ETA: 9:51 - loss: 4.1426 - acc: 0.2622"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-d8e504aadc6a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mgenerator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeras_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unet_RV.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'loss'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_generator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1500\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1449\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_with_new_api\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1450\u001b[0m           return tf_session.TF_SessionRunCallable(\n\u001b[0;32m-> 1451\u001b[0;31m               self._session._session, self._handle, args, status, None)\n\u001b[0m\u001b[1;32m   1452\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1453\u001b[0m           return tf_session.TF_DeprecatedSessionRunCallable(\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = unet()\n",
    "generator = keras_generator(1,4)\n",
    "model_checkpoint = ModelCheckpoint('unet_RV.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "model.fit_generator(generator,steps_per_epoch=1500,epochs=8,callbacks=[model_checkpoint], validation_data=(x_val,y_val),validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_model = load_model('unet_RV.hdf5')\n",
    "#new_model.summary()\n",
    "model = new_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10/10 [==============================] - 1s 148ms/step\n",
      "(256, 512, 20)\n",
      "[[128  64 128]\n",
      " [244  35 232]\n",
      " [ 70  70  70]\n",
      " [102 102 156]\n",
      " [190 153 153]\n",
      " [153 153 153]\n",
      " [250 170  30]\n",
      " [220 220   0]\n",
      " [107 142  35]\n",
      " [152 251 152]\n",
      " [ 70 130 180]\n",
      " [220  20  60]\n",
      " [255   0   0]\n",
      " [  0   0 142]\n",
      " [  0   0  70]\n",
      " [  0  60 100]\n",
      " [  0  80 100]\n",
      " [  0   0 230]\n",
      " [119  11  32]\n",
      " [  0   0   0]]\n",
      "[[19 19 19 ... 19 19 19]\n",
      " [19 19 19 ... 19 19 19]\n",
      " [19 19 19 ... 19 19 19]\n",
      " ...\n",
      " [19 19 19 ... 19 19 19]\n",
      " [19 19 19 ... 19 19 19]\n",
      " [19 19 19 ... 19 19 19]]\n",
      "[[    0 41923]\n",
      " [    1  3117]\n",
      " [    2 35262]\n",
      " [    8 10858]\n",
      " [    9   240]\n",
      " [   10  2338]\n",
      " [   11    28]\n",
      " [   13 23228]\n",
      " [   19 14078]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/anaconda3/lib/python3.6/site-packages/skimage/io/_plugins/matplotlib_plugin.py:51: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  out_of_range_float = (np.issubdtype(image.dtype, np.float) and\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAagAAADhCAYAAACdkiHQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSAooEREJkgJKRESC9P+0R6Ke8JRV4gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea9c6fe320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results = model.predict(x_val,verbose=1)\n",
    "print(results[1].shape)\n",
    "results = np.argmax(results,axis=3)\n",
    "results=results.astype(int)\n",
    "#res_image=np.argmax(results[0], axis=2)\n",
    "colorImage(x_val[1], results[1], 'classes.txt', 'colors.txt')\n",
    "print(results[1])\n",
    "unique, counts = np.unique(results[1], return_counts=True)\n",
    "\n",
    "print(np.asarray((unique, counts)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_pred=model.predict(x_val,verbose=1)\n",
    "x_pred = np.argmax(x_pred,axis=3)\n",
    "x_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_up = UpscaleImg(x_pred[0], 4,False)\n",
    "x_up.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "imshow(x_up)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val, y_val, filenames = importBatch(500,0,0,'val',4)\n",
    "x_pred = model.predict(x_val,verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "new_x=np.argmax(x_pred,axis=3)\n",
    "new_x.shape\n",
    "new_new_x = np.zeros((new_x.shape[0],new_x.shape[1]*4,new_x.shape[2]*4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for i in range(x_pred.shape[0]):\n",
    "    new_new_x[i]=UpscaleImg(new_x[i],4,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating 500 pairs of images...\n",
      "Images Processed: 500  \n",
      "\n",
      "\b-------------- ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------- \n",
      "\b              |  u   |  e   |  r   |  o   |  s   |  d   |  g   |  r   |  s   |  p   |  r   |  b   |  w   |  f   |  g   |  b   |  t   |  p   |  p   |  t   |  t   |  v   |  t   |  s   |  p   |  r   |  c   |  t   |  b   |  c   |  t   |  t   |  m   |  b   | Prior |\n",
      "\b-------------- ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------- \n",
      "\b    unlabeled | 0.90   0.03   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.05   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.3292 \n",
      "\b  ego vehicle | 0.18   0.56   0.10   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.14   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0473 \n",
      "\brectification | 0.00   0.00   0.92   0.00   0.00   0.00   0.00   0.00   0.04   0.00   0.02   0.00   0.00   0.02   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.1916 \n",
      "\b   out of roi | 0.06   0.12   0.46   0.00   0.00   0.00   0.00   0.00   0.07   0.01   0.00   0.00   0.00   0.27   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0064 \n",
      "\b       static | 0.00   0.05   0.69   0.00   0.00   0.00   0.00   0.00   0.11   0.00   0.00   0.00   0.00   0.13   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0072 \n",
      "\b      dynamic | 0.00   0.02   0.73   0.00   0.00   0.00   0.00   0.00   0.15   0.00   0.00   0.00   0.00   0.09   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0129 \n",
      "\b       ground | 0.00   0.00   0.72   0.00   0.00   0.00   0.00   0.00   0.26   0.00   0.01   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0017 \n",
      "\b         road | 0.00   0.01   0.80   0.00   0.00   0.00   0.00   0.00   0.09   0.00   0.01   0.00   0.00   0.09   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0058 \n",
      "\b     sidewalk | 0.00   0.00   0.13   0.00   0.00   0.00   0.00   0.00   0.83   0.00   0.00   0.00   0.00   0.02   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.1513 \n",
      "\b      parking | 0.07   0.24   0.07   0.00   0.00   0.00   0.00   0.00   0.29   0.26   0.00   0.00   0.00   0.07   0.00   0.00   0.00   0.00   0.00   0.02   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0073 \n",
      "\b   rail track | 0.00   0.00   0.09   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.89   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0293 \n",
      "\b     building | 0.00   0.01   0.57   0.00   0.00   0.00   0.00   0.00   0.05   0.00   0.00   0.00   0.00   0.36   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0113 \n",
      "\b         wall | 0.00   0.00   0.40   0.00   0.00   0.00   0.00   0.00   0.11   0.00   0.00   0.00   0.00   0.48   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0019 \n",
      "\b        fence | 0.01   0.01   0.09   0.00   0.00   0.00   0.00   0.00   0.02   0.00   0.00   0.00   0.00   0.86   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0570 \n",
      "\b   guard rail | 0.00   0.00   0.55   0.00   0.00   0.00   0.00   0.00   0.05   0.00   0.01   0.00   0.00   0.39   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0026 \n",
      "\b       bridge | 0.00   0.00   0.53   0.00   0.00   0.00   0.00   0.00   0.06   0.00   0.00   0.00   0.00   0.40   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0034 \n",
      "\b       tunnel | 0.00   0.01   0.64   0.00   0.00   0.00   0.00   0.00   0.06   0.00   0.01   0.00   0.00   0.29   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0010 \n",
      "\b         pole | 0.00   0.00   0.13   0.00   0.00   0.00   0.00   0.00   0.05   0.00   0.00   0.00   0.00   0.81   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0007 \n",
      "\b    polegroup | 0.01   0.03   0.24   0.00   0.00   0.00   0.00   0.00   0.17   0.00   0.00   0.00   0.00   0.54   0.00   0.00   0.00   0.00   0.00   0.01   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.0062 \n",
      "\btraffic light | 0.12   0.03   0.12   0.00   0.00   0.00   0.00   0.00   0.02   0.00   0.00   0.00   0.00   0.08   0.00   0.00   0.00   0.00   0.00   0.63   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00   0.00  0.1258 \n",
      "\b-------------- ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ ------ -------  \n",
      "\n",
      "classes          IoU      nIoU\n",
      "--------------------------------\n",
      "road          : 0.000      nan\n",
      "sidewalk      : 0.805      nan\n",
      "building      : 0.004      nan\n",
      "wall          : 0.000      nan\n",
      "fence         : 0.646      nan\n",
      "pole          : 0.000      nan\n",
      "traffic light : 0.625      nan\n",
      "traffic sign  :   nan      nan\n",
      "vegetation    :   nan      nan\n",
      "terrain       :   nan      nan\n",
      "sky           :   nan      nan\n",
      "person        :   nan      nan\n",
      "rider         :   nan      nan\n",
      "car           :   nan      nan\n",
      "truck         :   nan      nan\n",
      "bus           :   nan      nan\n",
      "train         :   nan      nan\n",
      "motorcycle    :   nan      nan\n",
      "bicycle       :   nan      nan\n",
      "--------------------------------\n",
      "Score Average : 0.297      nan\n",
      "--------------------------------\n",
      "\n",
      "\n",
      "categories       IoU      nIoU\n",
      "--------------------------------\n",
      "flat          : 0.781      nan\n",
      "construction  : 0.642      nan\n",
      "object        : 0.621      nan\n",
      "nature        :   nan      nan\n",
      "sky           :   nan      nan\n",
      "human         :   nan      nan\n",
      "vehicle       :   nan      nan\n",
      "--------------------------------\n",
      "Score Average : 0.682      nan\n",
      "--------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#new_new_x = new_new_x.astype(int)\n",
    "def eval_model(model):    \n",
    "        cityscapesPath = os.environ['CITYSCAPES_DATASET']        \n",
    "        for i in range(len(filenames)):\n",
    "            impath = os.path.join(cityscapesPath,'results', filenames[i].split('/')[7]+'.png')           \n",
    "            imsave(impath, new_new_x[i])\n",
    "%run cityscapesscripts/evaluation/evalPixelLevelSemanticLabeling > output.txt\n",
    "#eval_model(new_model)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def isfloat(value):\n",
    "    try:\n",
    "        float(value)\n",
    "        return True\n",
    "    except ValueError:\n",
    "        return False\n",
    "with open('output.txt', 'r') as myfile:\n",
    "    str=myfile.read().replace('\\n', '')\n",
    "#37\n",
    "str=str.split('|')\n",
    "str=str[37:70]\n",
    "str[32]=str[32][:-1322]\n",
    "a = []\n",
    "for s in str:\n",
    "    a.append(s.split(' '))\n",
    "cl =[]\n",
    "for k in a:\n",
    "    cl.append([ x for x in k if isfloat(x) ])\n",
    "mtrx = np.asarray(cl)\n",
    "mtrx.shape\n",
    "mt = np.zeros((33,35))\n",
    "for i in range(33):\n",
    "    for j in range(35):\n",
    "        mt[i][j]=int(mtrx[i][j].astype('float32')*255)\n",
    "plt.figure(figsize=(20, 20))\n",
    "plt.imshow(mt)\n",
    "strs=' |  u   |  e   |  r   |  o   |  s   |  d   |  g   |  r   |  s   |  p   |  r   |  b   |  w   |  f   |  g   |  b   |  t   |  p   |  p   |  t   |  t   |  v   |  t   |  s   |  p   |  r   |  c   |  t   |  b   |  c   |  t   |  t   |  m   |  b   ||'\n",
    "strs=strs.split(' ')\n",
    "strs = [x for x in strs if x.isalpha()]\n",
    "print(len(strs))\n",
    "sts =['unlabeled','ego vehicle','rectification','static','dynamic','ground','road','sidewalk','parking','rail_track','building','wall','fence','guard_rail','bridge','pole','polegroup','traffic_light','traffic_sign','vegetation','terrain','sky','person','rider','car','truck','bus','caravan','trailer','train','motorcycle','bicycle']\n",
    "plt.xticks(np.arange(35), sts, rotation=45, fontsize=25)\n",
    "plt.yticks(np.arange(33), strs, fontsize=25)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_val.shape,new_new_x.shape\n",
    "\n",
    "for i in [1,15,20,42]:\n",
    "    colorImage(UpscaleImg(x_val[i],4,1), new_new_x[i], 'classes.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.python.client import device_lib\n",
    "\n",
    "device_lib.list_local_devices()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'args' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9df1aafcdd62>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rvygon/SiriusCV/eval.py\u001b[0m in \u001b[0;36meval_preds\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0mgroundTruthImgList\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroundTruthSearch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mgt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgroundTruthImgList\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mpredictionImgList\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgetPrediction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0miou_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredictionImgList\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/rvygon/SiriusCV/eval.py\u001b[0m in \u001b[0;36mgetPrediction\u001b[0;34m(groundTruthFile)\u001b[0m\n\u001b[1;32m     29\u001b[0m     \u001b[0mpredictionFile\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m     \u001b[0;32mfor\u001b[0m \u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilenames\u001b[0m \u001b[0;32min\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredictionWalk\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     32\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfnmatch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfilter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilenames\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilePattern\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     33\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mpredictionFile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'args' is not defined"
     ]
    }
   ],
   "source": [
    "score = eval_preds()\n",
    "print(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
