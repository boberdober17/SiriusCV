{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CITYSCAPES_DATASET=/home/rvygon/data/\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import *\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# from keras import backend as keras\n",
    "import time\n",
    "import functools\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "%env CITYSCAPES_DATASET = /home/rvygon/data/\n",
    "from tensorflow.metrics import *\n",
    "batch_size = 2\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_image(image, label, width_shift_range, height_shift_range):\n",
    "    \"\"\"horisontal or vertical shift\"\"\"\n",
    "    if width_shift_range or height_shift_range:\n",
    "        if width_shift_range:\n",
    "            width_shift_range = tf.random_uniform([], -width_shift_range * img_shape[1], width_shift_range * img_shape[1])\n",
    "        if height_shift_range:\n",
    "            height_shift_range = tf.random_uniform([], -height_shift_range * img_shape[0], height_shift_range * img_shape[0])\n",
    "        image = tf.contrib.image.translate(image, [width_shift_range, height_shift_range])\n",
    "        label = tf.contrib.image.translate(label, [width_shift_range, height_shift_range])\n",
    "    return image, label\n",
    "\n",
    "def flip_img(horizontal_flip, image, label):\n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "        image, label = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                   lambda: (tf.image.flip_left_right(image), tf.image.flip_left_right(label)),\n",
    "                                   lambda: (image, label))\n",
    "    return image, label            \n",
    "\n",
    "def crop_img(crop_rate, image, label):\n",
    "    if crop_rate is not None:\n",
    "        image = tf.image.resize_images(tf.image.central_crop(image, crop_rate), (img_shape[0], img_shape[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        label = tf.image.resize_images(tf.image.central_crop(label, crop_rate), (img_shape[0], img_shape[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "def _augment(image,\n",
    "             label,\n",
    "             hue_delta=0,\n",
    "             horisontal_flip=False,\n",
    "             width_shift_range=0,\n",
    "             height_shift_range=0,\n",
    "             crop_rate=None):\n",
    "    if hue_delta:\n",
    "        image = tf.image.random_hue(image, hue_delta)\n",
    "    image, label = flip_img(horisontal_flip, image, label)\n",
    "    image, label = shifted_image(image, label, width_shift_range, height_shift_range)\n",
    "    image, label = crop_img(crop_rate, image, label)\n",
    "    return image, label\n",
    "def to_tensor(image, label):\n",
    "    return image, label\n",
    "\n",
    "def get_dataset(images, labels,\n",
    "                preproc_fn=functools.partial(_augment),\n",
    "                threads=5,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True):\n",
    "    num_x = len(images)\n",
    "    features_placeholder = tf.placeholder(images.dtype, images.shape)\n",
    "    labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "    \n",
    "#     dataset = dataset.map(to_tensor, num_parallel_calls=threads)\n",
    "   # dataset = dataset.map(preproc_fn)\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(num_x)\n",
    "    \n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "    iterator = dataset.make_initializable_iterator()\n",
    "\n",
    "    sess.run(iterator.initializer, feed_dict={features_placeholder: images,\n",
    "                                          labels_placeholder: labels})\n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell once\n",
    "#%run  cityscapesscripts/preparation/createTrainIdLabelImgs\n",
    "def upd_print(str):\n",
    "            sys.stdout.write('\\r')       \n",
    "            sys.stdout.write(str)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (256, 512, 3)\n",
    "batch_size = 1\n",
    "total_size = 2000\n",
    "val_size = 500\n",
    "scale_rate = 4\n",
    "verbose = 1\n",
    "start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files input -  100\n",
      "loaded files input -  200\n",
      "loaded files input -  300\n",
      "loaded files input -  400\n",
      "loaded files input -  500\n",
      "loaded files input -  600\n",
      "loaded files input -  700\n",
      "loaded files input -  800\n",
      "loaded files input -  900\n",
      "loaded files input -  1000\n",
      "loaded files input -  1100\n",
      "loaded files input -  1200\n",
      "loaded files input -  1300\n",
      "loaded files input -  1400\n",
      "loaded files input -  1500\n",
      "loaded files input -  1600\n",
      "loaded files input -  1700\n",
      "loaded files input -  1800\n",
      "loaded files input -  1900\n",
      "loaded files input -  2000\n",
      "loaded files output -  100\n",
      "loaded files output -  200\n",
      "loaded files output -  300\n",
      "loaded files output -  400\n",
      "loaded files output -  500\n",
      "loaded files output -  600\n",
      "loaded files output -  700\n",
      "loaded files output -  800\n",
      "loaded files output -  900\n",
      "loaded files output -  1000\n",
      "loaded files output -  1100\n",
      "loaded files output -  1200\n",
      "loaded files output -  1300\n",
      "loaded files output -  1400\n",
      "loaded files output -  1500\n",
      "loaded files output -  1600\n",
      "loaded files output -  1700\n",
      "loaded files output -  1800\n",
      "loaded files output -  1900\n",
      "loaded files output -  2000\n",
      "loaded files input -  100\n",
      "loaded files input -  200\n",
      "loaded files input -  300\n",
      "loaded files input -  400\n",
      "loaded files input -  500\n",
      "loaded files output -  100\n",
      "loaded files output -  200\n",
      "loaded files output -  300\n",
      "loaded files output -  400\n",
      "loaded files output -  500\n"
     ]
    }
   ],
   "source": [
    "x_train_data, y_train_data = importBatch(total_size, start_index, verbose,'train', scale_rate)\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "y_train_data = to_categorical(y_train_data)\n",
    "x_train_data = x_train_data.astype('uint8')\n",
    "y_train_data = y_train_data.astype('uint8')\n",
    "\n",
    "\n",
    "x_val_data, y_val_data, files = importBatch(val_size, start_index, verbose, 'val', scale_rate)\n",
    "y_val_data = to_categorical(y_val_data)\n",
    "x_val_data = x_val_data.astype('uint8')\n",
    "y_val_data = y_val_data.astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNET https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "#def IoU_metric(y_true, y_preds):\n",
    "    #print(y_true.shape)\n",
    "   # return tf.metrics.mean_iou(y_true,y_preds,20)\n",
    "def unet(pretrained_weights=None, input_size=img_shape):\n",
    "    inputs = Input(input_size)\n",
    "  \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)    \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))#drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(20, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model([inputs], [conv10])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy', 'mean_iou'])\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "    'hue_delta': 0.2,\n",
    "    'horisontal_flip': True,\n",
    "    'crop_rate' : 0.5\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'sess' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-ae65953d95cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m                        \u001b[0my_train_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m                        \u001b[0mpreproc_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtr_preprocessing_fn\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m                        batch_size=1)\n\u001b[0m\u001b[1;32m      5\u001b[0m val_ds = get_dataset(x_val_data,\n\u001b[1;32m      6\u001b[0m                       \u001b[0my_val_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-799bf9e00c12>\u001b[0m in \u001b[0;36mget_dataset\u001b[0;34m(images, labels, preproc_fn, threads, batch_size, shuffle)\u001b[0m\n\u001b[1;32m     59\u001b[0m     \u001b[0miterator\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_initializable_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 61\u001b[0;31m     sess.run(iterator.initializer, feed_dict={features_placeholder: images,\n\u001b[0m\u001b[1;32m     62\u001b[0m                                           labels_placeholder: labels})\n\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'sess' is not defined"
     ]
    }
   ],
   "source": [
    "train_ds = get_dataset(x_train_data, \n",
    "                       y_train_data,\n",
    "                       preproc_fn=tr_preprocessing_fn,\n",
    "                       batch_size=1)\n",
    "val_ds = get_dataset(x_val_data,\n",
    "                      y_val_data,\n",
    "                      preproc_fn=val_preprocessing_fn,\n",
    "                      batch_size=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST #\n",
    "\"\"\"\n",
    "temp_ds = get_dataset(x_train_data,\n",
    "                     y_train_data,\n",
    "                     preproc_fn=tr_preprocessing_fn,\n",
    "                     batch_size=10,\n",
    "                     shuffle=False)\n",
    "data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "for i in range(10):\n",
    "    with tf.Session() as sess:\n",
    "        batch_of_imgs, batch_of_labels = sess.run(next_element)        \n",
    "        print(batch_of_imgs.shape)\n",
    "        img = batch_of_imgs[i]\n",
    "        label = batch_of_labels[i]\n",
    "        label = np.argmax(label, axis=2)        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(label)\n",
    "        plt.title(\"Masked\")\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unknown metric function:mean_iou",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-0ea7d8cf6492>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mcsv_logger\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCSVLogger\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'log.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mappend\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseparator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0munet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m#load_model('unet_tensorflow.hdf5')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mmodel_checkpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModelCheckpoint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'unet_tensorflow.hdf5'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmonitor\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mean_iou'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave_best_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3000\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_checkpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcsv_logger\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-10-fcff5f7f1c12>\u001b[0m in \u001b[0;36munet\u001b[0;34m(pretrained_weights, input_size)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mconv10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 50\u001b[0;31m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mAdam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1e-3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'mean_iou'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m     \u001b[0;32mif\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/training/checkpointable/base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    362\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    363\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 364\u001b[0;31m       \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    365\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    366\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    538\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetrics_updates\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mmetric_fn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 540\u001b[0;31m         \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    541\u001b[0m         \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    519\u001b[0m                   metric_fn)\n\u001b[1;32m    520\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m               \u001b[0mmetric_fn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmetrics_module\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    522\u001b[0m               weighted_metric_fn = training_utils.weighted_masked_objective(\n\u001b[1;32m    523\u001b[0m                   metric_fn)\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(identifier)\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    108\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstring_types\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 109\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdeserialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    110\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midentifier\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0midentifier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/metrics.py\u001b[0m in \u001b[0;36mdeserialize\u001b[0;34m(config, custom_objects)\u001b[0m\n\u001b[1;32m     98\u001b[0m       \u001b[0mmodule_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mglobals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m       \u001b[0mcustom_objects\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcustom_objects\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m       printable_module_name='metric function')\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/utils/generic_utils.py\u001b[0m in \u001b[0;36mdeserialize_keras_object\u001b[0;34m(identifier, module_objects, custom_objects, printable_module_name)\u001b[0m\n\u001b[1;32m    191\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mfn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m         raise ValueError('Unknown ' + printable_module_name + ':' +\n\u001b[0;32m--> 193\u001b[0;31m                          function_name)\n\u001b[0m\u001b[1;32m    194\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    195\u001b[0m   \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Unknown metric function:mean_iou"
     ]
    }
   ],
   "source": [
    "print('Starting training...')\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "\n",
    "model = unet()#load_model('unet_tensorflow.hdf5')\n",
    "model_checkpoint = ModelCheckpoint('unet_tensorflow.hdf5', monitor='mean_iou',verbose=1, save_best_only=True)\n",
    "history = model.fit(train_ds, steps_per_epoch=3000,epochs=8,callbacks=[model_checkpoint, csv_logger], validation_data=val_ds,validation_steps=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = unet()\n",
    "# generator = keras_generator(1,4)\n",
    "# model_checkpoint = ModelCheckpoint('unet_tensorflow.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "# history = model.fit_generator(generator,steps_per_epoch=10,epochs=8,callbacks=[model_checkpoint])#, validation_data=(x_val,y_val),validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "500/500 [==============================] - 13s 26ms/step\n",
      "processed 499 images\n",
      "road : 0.3356632093321018\n",
      "sidewalk : 0.0001940447746781639\n",
      "building : 0.40819838854180157\n",
      "wall : 0.0\n",
      "fence : 0.0\n",
      "pole : 3.9494071081483315e-05\n",
      "traffic light : 0.0\n",
      "traffic sign : 0.0\n",
      "vegetation : 0.0005617600047899008\n",
      "terrain : 0.0\n",
      "sky : 0.010715501860126804\n",
      "person : 1.4839133980875212e-05\n",
      "rider : 0.0002583420892902456\n",
      "car : 0.11293464095651731\n",
      "truck : 0.0\n",
      "bus : 6.752194463200541e-07\n",
      "train : 1.051635292880429e-07\n",
      "motorcycle : 0.0\n",
      "bicycle : 7.377713530556818e-06\n",
      "0.04342993490309287\n"
     ]
    }
   ],
   "source": [
    "SCALE = 4\n",
    "#tic = time.time()\n",
    "#x_val, y_val, filenames = importBatch(500,0,0,'val',SCALE)\n",
    "#toc = time.time()\n",
    "#print('Load validation batch:', toc - tic)\n",
    "def eval_model(model):          \n",
    "        print(1)\n",
    "        x_pred = model.predict(x_val_data,verbose=1)        \n",
    "        new_x=np.argmax(x_pred,axis=3)\n",
    "        \n",
    "        \"\"\" UPSCALING\n",
    "        new_new_x = np.zeros((new_x.shape[0],new_x.shape[1]*SCALE,new_x.shape[2]*SCALE))\n",
    "        \n",
    "        for i in range(x_pred.shape[0]):\n",
    "            new_new_x[i]=UpscaleImg(new_x[i],SCALE,0)\n",
    "            upd_print((\"Upscaled %d images\" % i))\n",
    "        print()\n",
    "        new_new_x=new_new_x.astype(int)\"\"\"\n",
    "        \n",
    "        new_x=new_x.astype(int)        \n",
    "        \n",
    "        \"\"\"   SAVE\n",
    "        cityscapesPath = os.environ['CITYSCAPES_DATASET']        \n",
    "        for i in range(len(filenames)):\n",
    "            impath = os.path.join(cityscapesPath,'results', filenames[i].split('/')[7]+'.png')           \n",
    "            imsave(impath, new_new_x[i])\n",
    "            upd_print(\"Saved %d images\" % i)            \n",
    "        print()\n",
    "        toc = time.time()\n",
    "        print('Save files:', toc -tic) \"\"\"\n",
    "        y_val = np.argmax(y_val_data,axis=3)\n",
    "        score = eval_preds(new_x,y_val)        \n",
    "        return score\n",
    "\n",
    "#model = load_model('unet_tensorflow.hdf5')\n",
    "print(eval_model(model))\n",
    "#print(y_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
