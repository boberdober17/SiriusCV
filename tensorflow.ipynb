{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: CITYSCAPES_DATASET=/home/rvygon/data/\n",
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import os, glob, sys\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import h5py\n",
    "import tensorflow as tf\n",
    "%matplotlib inline\n",
    "import skimage\n",
    "from skimage.io import imread, imshow, imsave\n",
    "from tensorflow.python.keras.models import *\n",
    "from tensorflow.python.keras.layers import *\n",
    "from tensorflow.python.keras.optimizers import *\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
    "# from keras import backend as keras\n",
    "import time\n",
    "import functools\n",
    "from eval import *\n",
    "from ShowColors import *\n",
    "from ImportUtil import *\n",
    "%env CITYSCAPES_DATASET = /home/rvygon/data/\n",
    "from tensorflow.metrics import *\n",
    "batch_size = 2\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shifted_image(image, label, width_shift_range, height_shift_range):\n",
    "    \"\"\"horisontal or vertical shift\"\"\"\n",
    "    if width_shift_range or height_shift_range:\n",
    "        if width_shift_range:\n",
    "            width_shift_range = tf.random_uniform([], -width_shift_range * img_shape[1], width_shift_range * img_shape[1])\n",
    "        if height_shift_range:\n",
    "            height_shift_range = tf.random_uniform([], -height_shift_range * img_shape[0], height_shift_range * img_shape[0])\n",
    "        image = tf.contrib.image.translate(image, [width_shift_range, height_shift_range])\n",
    "        label = tf.contrib.image.translate(label, [width_shift_range, height_shift_range])\n",
    "    return image, label\n",
    "\n",
    "def flip_img(horizontal_flip, image, label):\n",
    "    if horizontal_flip:\n",
    "        flip_prob = tf.random_uniform([], 0.0, 1.0)\n",
    "        image, label = tf.cond(tf.less(flip_prob, 0.5),\n",
    "                                   lambda: (tf.image.flip_left_right(image), tf.image.flip_left_right(label)),\n",
    "                                   lambda: (image, label))\n",
    "    return image, label            \n",
    "\n",
    "def crop_img(crop_rate, image, label):\n",
    "    if crop_rate is not None:\n",
    "        image = tf.image.resize_images(tf.image.central_crop(image, crop_rate), (img_shape[0], img_shape[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "        label = tf.image.resize_images(tf.image.central_crop(label, crop_rate), (img_shape[0], img_shape[1]), method=tf.image.ResizeMethod.NEAREST_NEIGHBOR)\n",
    "    return image, label\n",
    "\n",
    "def _augment(image,\n",
    "             label,\n",
    "             hue_delta=0,\n",
    "             horisontal_flip=False,\n",
    "             width_shift_range=0,\n",
    "             height_shift_range=0,\n",
    "             crop_rate=None):\n",
    "    if hue_delta:\n",
    "        image = tf.image.random_hue(image, hue_delta)\n",
    "    image, label = flip_img(horisontal_flip, image, label)\n",
    "    image, label = shifted_image(image, label, width_shift_range, height_shift_range)\n",
    "    image, label = crop_img(crop_rate, image, label)\n",
    "    return image, label\n",
    "def to_tensor(image, label):\n",
    "    return image, label\n",
    "\n",
    "def get_dataset(images, labels,\n",
    "                preproc_fn=functools.partial(_augment),\n",
    "                threads=5,\n",
    "                batch_size=batch_size,\n",
    "                shuffle=True):\n",
    "    num_x = len(images)\n",
    "    features_placeholder = tf.placeholder(images.dtype, images.shape)\n",
    "    labels_placeholder = tf.placeholder(labels.dtype, labels.shape)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "   \n",
    "    #dataset = dataset.map(to_tensor, num_parallel_calls=threads)\n",
    "   # dataset = dataset.map(preproc_fn)\n",
    "#     if shuffle:\n",
    "#         dataset = dataset.shuffle(num_x)\n",
    "    \n",
    "   \n",
    "   \n",
    "\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run this cell once\n",
    "#%run  cityscapesscripts/preparation/createTrainIdLabelImgs\n",
    "def upd_print(str):\n",
    "            sys.stdout.write('\\r')       \n",
    "            sys.stdout.write(str)\n",
    "            sys.stdout.flush()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "img_shape = (256, 512, 3)\n",
    "batch_size = 1\n",
    "total_size = 2000\n",
    "val_size = 500\n",
    "scale_rate = 4\n",
    "verbose = 1\n",
    "start_index = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loaded files input -  100\n",
      "loaded files input -  200\n",
      "loaded files input -  300\n",
      "loaded files input -  400\n",
      "loaded files input -  500\n",
      "loaded files input -  600\n",
      "loaded files input -  700\n",
      "loaded files input -  800\n",
      "loaded files input -  900\n",
      "loaded files input -  1000\n",
      "loaded files input -  1100\n",
      "loaded files input -  1200\n",
      "loaded files input -  1300\n",
      "loaded files input -  1400\n",
      "loaded files input -  1500\n",
      "loaded files input -  1600\n",
      "loaded files input -  1700\n",
      "loaded files input -  1800\n",
      "loaded files input -  1900\n",
      "loaded files input -  2000\n",
      "loaded files output -  100\n",
      "loaded files output -  200\n",
      "loaded files output -  300\n",
      "loaded files output -  400\n",
      "loaded files output -  500\n",
      "loaded files output -  600\n",
      "loaded files output -  700\n",
      "loaded files output -  800\n",
      "loaded files output -  900\n",
      "loaded files output -  1000\n",
      "loaded files output -  1100\n",
      "loaded files output -  1200\n",
      "loaded files output -  1300\n",
      "loaded files output -  1400\n",
      "loaded files output -  1500\n",
      "loaded files output -  1600\n",
      "loaded files output -  1700\n",
      "loaded files output -  1800\n",
      "loaded files output -  1900\n",
      "loaded files output -  2000\n",
      "loaded files input -  100\n",
      "loaded files input -  200\n",
      "loaded files input -  300\n",
      "loaded files input -  400\n",
      "loaded files input -  500\n",
      "loaded files output -  100\n",
      "loaded files output -  200\n",
      "loaded files output -  300\n",
      "loaded files output -  400\n",
      "loaded files output -  500\n"
     ]
    }
   ],
   "source": [
    "x_train_data, y_train_data = importBatch(total_size, start_index, verbose,'train', scale_rate)\n",
    "from tensorflow.python.keras.utils import to_categorical\n",
    "y_train_data = to_categorical(y_train_data)\n",
    "x_train_data = x_train_data.astype('uint8')\n",
    "y_train_data = y_train_data.astype('uint8')\n",
    "\n",
    "\n",
    "x_val_data, y_val_data, files = importBatch(val_size, start_index, verbose, 'val', scale_rate)\n",
    "y_val_data = to_categorical(y_val_data)\n",
    "x_val_data = x_val_data.astype('uint8')\n",
    "y_val_data = y_val_data.astype('uint8')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#UNET https://github.com/zhixuhao/unet/blob/master/model.py\n",
    "#def IoU_metric(y_true, y_preds):\n",
    "    #print(y_true.shape)\n",
    "   # return tf.metrics.mean_iou(y_true,y_preds,20)\n",
    "def unet(pretrained_weights=None, input_size=img_shape):\n",
    "    inputs = Input(input_size)\n",
    "  \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)    \n",
    "    conv1 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n",
    "    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n",
    "    conv2 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n",
    "    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n",
    "    conv3 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n",
    "    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n",
    "    conv4 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n",
    "    drop4 = Dropout(0.5)(conv4)\n",
    "    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n",
    "\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n",
    "    conv5 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n",
    "    drop5 = Dropout(0.5)(conv5)\n",
    "\n",
    "    up6 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))#drop5))\n",
    "    merge6 = concatenate([drop4,up6], axis = 3)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n",
    "    conv6 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n",
    "\n",
    "    up7 = Conv2D(32, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n",
    "    merge7 = concatenate([conv3,up7], axis = 3)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n",
    "    conv7 = Conv2D(32, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n",
    "\n",
    "    up8 = Conv2D(16, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n",
    "    merge8 = concatenate([conv2,up8], axis = 3)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n",
    "    conv8 = Conv2D(16, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n",
    "\n",
    "    up9 = Conv2D(8, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n",
    "    merge9 = concatenate([conv1,up9], axis = 3)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n",
    "    conv9 = Conv2D(8, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    #conv9 = Conv2D(2, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n",
    "    conv10 = Conv2D(20, 1, activation = 'sigmoid')(conv9)\n",
    "\n",
    "    model = Model([inputs], [conv10])\n",
    "\n",
    "    model.compile(optimizer = Adam(lr = 1e-3), loss = 'categorical_crossentropy', metrics = ['accuracy'])\n",
    "\n",
    "    if(pretrained_weights):\n",
    "        model.load_weights(pretrained_weights)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_cfg = {\n",
    "    'hue_delta': 0.2,\n",
    "    'horisontal_flip': True,\n",
    "    'crop_rate' : 0.5\n",
    "}\n",
    "tr_preprocessing_fn = functools.partial(_augment, **tr_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "val_cfg = {\n",
    "}\n",
    "val_preprocessing_fn = functools.partial(_augment, **val_cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = get_dataset(x_train_data, \n",
    "                       y_train_data,\n",
    "                       preproc_fn=tr_preprocessing_fn,\n",
    "                       batch_size=1)\n",
    "val_ds = get_dataset(x_val_data,\n",
    "                      y_val_data,\n",
    "                      preproc_fn=val_preprocessing_fn,\n",
    "                      batch_size=1)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TEST #\n",
    "\"\"\"\n",
    "temp_ds = get_dataset(x_train_data,\n",
    "                     y_train_data,\n",
    "                     preproc_fn=tr_preprocessing_fn,\n",
    "                     batch_size=10,\n",
    "                     shuffle=False)\n",
    "data_aug_iter = temp_ds.make_one_shot_iterator()\n",
    "next_element = data_aug_iter.get_next()\n",
    "for i in range(10):\n",
    "    with tf.Session() as sess:\n",
    "        batch_of_imgs, batch_of_labels = sess.run(next_element)        \n",
    "        print(batch_of_imgs.shape)\n",
    "        img = batch_of_imgs[i]\n",
    "        label = batch_of_labels[i]\n",
    "        label = np.argmax(label, axis=2)        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.imshow(img)\n",
    "        plt.title(\"Original\")\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.imshow(label)\n",
    "        plt.title(\"Masked\")\n",
    "        plt.show()\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting training...\n",
      "(2000, 256, 512, 3)\n",
      "Epoch 1/50\n",
      " 272/3000 [=>............................] - ETA: 4:57 - loss: 2.7242 - acc: 0.3754"
     ]
    }
   ],
   "source": [
    "print('Starting training...')\n",
    "from tensorflow.keras.callbacks import CSVLogger\n",
    "\n",
    "csv_logger = CSVLogger('log.csv', append=True, separator=';')\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    features_placeholder = tf.placeholder(x_train_data.dtype, x_train_data.shape)\n",
    "    labels_placeholder = tf.placeholder(y_train_data.dtype, y_train_data.shape)\n",
    "\n",
    "    dataset = tf.data.Dataset.from_tensor_slices((features_placeholder, labels_placeholder))\n",
    "    dataset = dataset.repeat().batch(batch_size)\n",
    "   \n",
    "    iterator1 = dataset.make_initializable_iterator()\n",
    "    sess.run(iterator1.initializer, feed_dict={features_placeholder: x_train_data,\n",
    "                                          labels_placeholder: y_train_data})\n",
    "    print(x_train_data.shape)\n",
    "    model = unet()#load_model('unet_tensorflow.hdf5')\n",
    "    model_checkpoint = ModelCheckpoint('unet_tensorflow.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "    \n",
    "    history = model.fit(iterator1, steps_per_epoch=3000,epochs=50,callbacks=[model_checkpoint, csv_logger])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# model = unet()\n",
    "# generator = keras_generator(1,4)\n",
    "# model_checkpoint = ModelCheckpoint('unet_tensorflow.hdf5', monitor='loss',verbose=1, save_best_only=True)\n",
    "# history = model.fit_generator(generator,steps_per_epoch=10,epochs=8,callbacks=[model_checkpoint])#, validation_data=(x_val,y_val),validation_steps=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "500/500 [==============================] - 13s 26ms/step\n",
      "processed 499 images\n",
      "road : 0.3356632093321018\n",
      "sidewalk : 0.0001940447746781639\n",
      "building : 0.40819838854180157\n",
      "wall : 0.0\n",
      "fence : 0.0\n",
      "pole : 3.9494071081483315e-05\n",
      "traffic light : 0.0\n",
      "traffic sign : 0.0\n",
      "vegetation : 0.0005617600047899008\n",
      "terrain : 0.0\n",
      "sky : 0.010715501860126804\n",
      "person : 1.4839133980875212e-05\n",
      "rider : 0.0002583420892902456\n",
      "car : 0.11293464095651731\n",
      "truck : 0.0\n",
      "bus : 6.752194463200541e-07\n",
      "train : 1.051635292880429e-07\n",
      "motorcycle : 0.0\n",
      "bicycle : 7.377713530556818e-06\n",
      "0.04342993490309287\n"
     ]
    }
   ],
   "source": [
    "SCALE = 4\n",
    "#tic = time.time()\n",
    "#x_val, y_val, filenames = importBatch(500,0,0,'val',SCALE)\n",
    "#toc = time.time()\n",
    "#print('Load validation batch:', toc - tic)\n",
    "def eval_model(model):          \n",
    "        print(1)\n",
    "        x_pred = model.predict(x_val_data,verbose=1)        \n",
    "        new_x=np.argmax(x_pred,axis=3)\n",
    "        \n",
    "        \"\"\" UPSCALING\n",
    "        new_new_x = np.zeros((new_x.shape[0],new_x.shape[1]*SCALE,new_x.shape[2]*SCALE))\n",
    "        \n",
    "        for i in range(x_pred.shape[0]):\n",
    "            new_new_x[i]=UpscaleImg(new_x[i],SCALE,0)\n",
    "            upd_print((\"Upscaled %d images\" % i))\n",
    "        print()\n",
    "        new_new_x=new_new_x.astype(int)\"\"\"\n",
    "        \n",
    "        new_x=new_x.astype(int)        \n",
    "        \n",
    "        \"\"\"   SAVE\n",
    "        cityscapesPath = os.environ['CITYSCAPES_DATASET']        \n",
    "        for i in range(len(filenames)):\n",
    "            impath = os.path.join(cityscapesPath,'results', filenames[i].split('/')[7]+'.png')           \n",
    "            imsave(impath, new_new_x[i])\n",
    "            upd_print(\"Saved %d images\" % i)            \n",
    "        print()\n",
    "        toc = time.time()\n",
    "        print('Save files:', toc -tic) \"\"\"\n",
    "        y_val = np.argmax(y_val_data,axis=3)\n",
    "        score = eval_preds(new_x,y_val)        \n",
    "        return score\n",
    "\n",
    "#model = load_model('unet_tensorflow.hdf5')\n",
    "print(eval_model(model))\n",
    "#print(y_val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
